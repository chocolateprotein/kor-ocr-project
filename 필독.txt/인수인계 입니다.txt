지금 파인 튜닝 하는 korean_g2데이터 셋은 outputchanel - 256, hiddensize -256 으로 구성되어있습니다. 커스텀 모델 구동시에 이값이 틀리면 이상한 값으로 출력되기 떄문에 조심하셔야 합니다. 인턴십 끝나기 전까지 완료 해놓고 가고싶었는ㄴ데 생각보다 늦어져서 죄송합니다.

커스텀 모델 사용은 run.py를 이용하시면되고 아마 코드를 읽어보시면 어떻게 사용하는지 알수있을것입니다!

사용할려는 모델의 py파일과 yaml 파일을 user_network_directory에 넣어서 사용하는데 yaml파일은 트레인 했을떄 opt값 기준으로 작성을 해서 넣으시면 됩니다.korean_g22파일이 현제 학습을 진행중인 opt값이라 계속 사용하셔도 무방합니다.(py파일도 포함)

현재 파인 튜닝 할려는 모델은 korean_g2모델로 학습할 데이터들은 글랜 서버에 보내놧으니 거기서 훈련 시키시면 됩니다.(회사 서버의 훈련이 끝나면)
깃허브에 푸쉬하는건 일단 제 깃에 올려놓았고 글랜 서버에도 있으니 사용하실떄 찾아서 사용하시면 됩니다.

모델 트레인을 하면은 saved_model 폴더에 입력하신 속성값대로 폴더가 생기면서 저장이됩니다. 그중 best_accuracy.pth 가 모델 훈련에서 나온 결과값 입니다.
craftmodel 은 책표지를 한번 훈련시킬 예정이며, korean g2 는 세개 데이터 전부 훈련시키면 될거같습니다. 

1번에서 말했던 채널값을 안맞추면 토치 사이즈 에러가 날것입니다! 그래서 훈련시킬떄 잘맞춰주셔야 해요,...

첫번째 test 트레인 시킨건 너무 적게 학습시킨거 같아서 더늘려서 학습을 진행은 해놨습니다. 결과를 보고 가고싶지만.. 너무 오래걸려서 craft 모델 학습후에 또 결과를 봐볼 예정입니다!

채널훈련값은 g2 채널에 맞춰서 256으로 디폴트값을 지정 해놓겠습니다. 만일 다른 모델로 훈련을 하고싶다면, train.py에 가셔서 바꾸시면 됩니다.

여기 user_network_directory 파일 안에 제가 속성에 맞춰서 만들어놓은 예시들이 있습니다. 참고하시면서 쓰시면 될것같아요!

아! 모델들은 각각 craft 모델이 detection 모델 korean_g2 모델이 reconition 모델입니다. 각각 파인튜닝 해서 사용하시면 될거같아요!

저는 일단 훈련진행을 메인 서버에서 하고 있는 synthetic 데이터는 none-vgg-bilstm-attn 식으로 훈련 시키고 있습니다. 물론 4만번이 충분하지 않을수 있습니다. 추후에 다른 데이터 들은 none-vgg-bilstm-ctc 방식으로 훈련시켜서 결과를 볼려고 했습니다.. 시간이 너무 짧네요..

모델들이 여러게 나와있지만 https://github.com/parksunwoo/ocr_kor 여기에 가보시면 이분이 친절하게 다 테스트를 해보셨더군요... 근데 저는 일단은 korean_g2 모델을 파인튜닝하는게 더 낫다고 보여집니다.

첫번째 훈련한 모델이 성능이 좋지는 않습니다.. 제가 보기엔 훈련 할떄 설정값을 다르게 넣어 그런가 싶기도 해서 여러번 시도를 해봤습니다.해서 꼭 훈련하실떄 값을 잘보면서 넣으셔야 좋은결과값이 나올거 같아요!

모델 train은 synthetic/makingtxt/deep-text-~~ 에 가시면 demo.sh 파일이 있을거에요 그거 이용하시면 됩니다. 

!!!!메인 트레인파일 11983 회사서버에서 트레이닝중
!!!!글랜서버 721477 크래프트 모델 트레이닝 중

데이터 구성은 현재 글랜 서버에 있는 데이터는 synthetic/makingtxt/ocr_kor/out 안에 있는 폴더들로 구성되어있습니다
booktrain,bookvalidate ==> 책표지 데이터, train,validate ==> trdg를 이용해 만든 텍스트 사진 , mdb파일이 다만들어져있어 경로지정만해서 학습 시키시면 됩니다.

deep-text-recognition 에 있는 synthetictrain,syntheticvalidate 데이터는 현제 메인 서버에서 recognition 모델을 훈련중인 데이터입니다.

훈련시킬떄 batch_max_length지정 book==> 100, trdg===>50, sythetic ==> 1100 위 훈련시킬때 옵션을 적어놓은걸 보시면 batch_max_length 값이 지정되있는걸 볼수 있습니다. 저기서 각 데이터를 훈련할떄 옵션으로 위에 값들을 사용하시면 됩니다.(사용을 안하시면 tensorsize 오류가떠서 훈련이 안됩니다.)

훈련 시킬떄 뒤에 test 값을 보고 싶으시면, https://github.com/parksunwoo/ocr_kor 이분 깃에 test.py 사용하는 법이 조금 나와있습니다.

!!!!CUDA_VISIBLE_DEVICES=0 python3 train.py  --train_data ../ocr_kor/TextRecognitionDataGenerator/out/booktrain   --valid_data ../ocr_kor/TextRecognitionDataGenerator/out/bookvalidate  --select_data /  --batch_ratio 1 --Transformation None --FeatureExtraction VGG --SequenceModeling BiLSTM --Prediction CTC --saved_model ./models/craft_mlt_25k.pth --FT --batch_max_length 200 --valInterval 2000 !!!
이 위에 써져있는 값이 craft 모델 훈련시킬떄 사용한 값입니다! 참고하셔서 사용하시면 될거같아요

현재 해결중인 문제는 커스텀 사용을 위한 모듈 속성값 입력에 있습니다. 제가 해볼려는것에 대한 데이터가 많이 없어서 최대한 해볼게요!(user_network_directory에 있는 py 파일 구성입니다.)



참고한 링크들 :
https://github.com/clovaai/deep-text-recognition-benchmark/issues/210
https://github.com/clovaai/deep-text-recognition-benchmark/issues/278
https://beok.tistory.com/109
https://velog.io/@hyunk-go/%ED%81%AC%EB%A1%A4%EB%A7%81-Tesseract-OCR-EasyOCR-OpenCV-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%ED%95%99%EC%8A%B5
https://github.com/clovaai/deep-text-recognition-benchmark
https://davelogs.tistory.com/78
위에는 모델 트레인 입니다.

https://python.plainenglish.io/create-synthetic-images-using-opencv-python-3e21f9bc18dd(이건 synthetic 만들떄 사용했어요 다갈긴했지만..)
https://github.com/JaidedAI/EasyOCR
https://ivo-lee.tistory.com/91 (이미지 리사이즈 필요할시 화질 변경법입니다.)

https://github.com/Belval/TextRecognitionDataGenerator(trdg기법입니다)

https://cchhoo407.tistory.com/37 (load_state_dict 에러 해결법 size mismatch)

그외 여러개가 있었는데 기억이 나질 않네요 ㅠㅠ


이 밑으로는 제가 하면서 생각한것들이나 알게된것들을 정리해봣어요~

회의  07/06
 , 교과서로 라밸링 중, ocr레포찾기, 종이에서 글자 추론하는 py, 손글씨무시, 텍스트는?컴퓨터기준, 자동화 코드가 주목적, 손글씨와 컴퓨터체 구분법(비전관련해서 구별할수있게), 텍스트 를 원문처럼 구현하는게 큰 목적이다, 	
장기적으로 보고 ocr에 초점을 맞춰서 하면된다.
-my
Easyocr 	트레인 데이터를 늘려보는 방식?
Tesseract 방식은 구동 확인
easyocr쪽이 훨씬더 정확성과 속도 차이를 보인다. 
데이터의 질?, 데이터 학습량의 문제?, 구동하는 jpg의 화질?, 

07/07 
추가 데이터 학습의 필요성?(https://velog.io/@bokyungkim/EasyOCR%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%B4-%ED%8B%B0%EC%BC%93-%EC%86%8D-%EB%AC%B8%EC%9E%90%EB%A5%BC-%ED%85%8D%EC%8A%A4%ED%8A%B8%ED%99%94-%ED%95%B4%EB%B3%B4%EC%9E%90)
-https://www.youtube.com/watch?v=pECt2rXbpTk : ocr성능 향상 리포트
De-noising output and labeling
Multi-task learning
Detection label ==> 문자영역 밖은 De-noising
디노이징을 이용한 문자 detection 성능향상
https://egloos.zum.com/incredible/v/7479749
모델은 동일시 사용 전처리를 de-noising으로 사용해서 결과값up?
De-noizing kaggle : https://www.kaggle.com/code/michalbrezk/denoise-images-using-autoencoders-tf-keras
내가 생각하는 계선법 de-noising + 추가 train 이면 성능이 향상될것으로 생각함 글랜이 걱정하는 필기체도 de-noising으로 없어질 가능성이 높게 본다.
Denoising autoencoders 를 이용한 문서 denoising 방법이 가장 유력쓰

7/8
Detection 인식 훈련, 극소적인 부분들은 drop하고 recognition 에서 찾는게 맞다
model train 으로 어느정도 커버가 된다, 모델에서 끌어올릴수 있는만큼 올리고 추후에 개선점을 찾아서 적용 시키는것이 맞다. 일반적인 데이터와 sythetic 데이터를 합쳐서 모델에 학습시켜보면 더 좋은 결과가 나올것 같다. pytorch tutorials, sythetic data!

7/12
34번 데이터 부터는 이미지 리사이즈 필요x, 그전꺼는 2480,3508식으로 바꾸어 줘야함
폴더안에 이상한 폴더가 있는것도 생각 —> 예외 처리를 해줘야함

1~25번 까지가 낙서 26~40번 까지가 형광펜 41~50 일반글자
낙서 총25개 형광펜 총 15개 일반 10개
Tainning = 낙서 20개 ,형광팬 = 12개 일반 8개 총 40개
Validation = 낙서 5개, 형광펜 = 3개  일반 2개 총 10개
형광펜 37까지

7/12
Synthetic data 외 추가적인 학습이 필요하다고 생각 책표지 이미지 training 약 4만장, validation
오늘의 문제점은 경로가 다르다는것! mdb데이터를 다시 만들어서 실행해봐야겟다.
* 문제 로직에 접근할때 우선 결과를 먼저보고 그다음 자기가 만들고자 하는것을 본다, 꼭 짜여져 있는 코드에 구애받지 말고 자신이 원하는 출력을 얻기만하면 그만이다. 방법은 정형화 되어있지 않다
7/13
데이터 문제에서 경로는 다시설정후에 
문제점 https://beok.tistory.com/100 여기서 보고 해결
Torch size 문제는 DataParallel ==> gpu 사용 갯수 문제이다 model에서 주석처리를 해주니 해결 https://log-mylife.tistory.com/entry/Ntire-dataset-testpy-%EA%B5%AC%EB%8F%99%ED%95%B4%EB%B3%B4%EA%B8%B0
은 안되는 경우도 있어서 https://bo-10000.tistory.com/112 참조


7/15
학습을 진행해봤지만 학습이 제대로 되지않았다, 버그가 있는것같다.


7/18	주말내에 해서 어떻게 할건지 글랜과 상의를 통해서 글랜한테부탁해서 attn에서 학습이 돌아가는것을 확인, 추가 이제 학습은 attn으로 진행될 예정이며 책표지 4만장과 textgenerator를 이용한 데이터 (일반 글자 2만장 skew데이터 1만장 syn데이터 1만장으로 구비)
00 -총류
01 - 철학
02 - 종교
03 - 사회과학
04 - 자연과학
05 - 기술과학
06 - 예술
07 - 언어
08 - 문학
09 - 역사
10 - 기타

7/20일회의
아리는 금주까지 개발에 집중
피터-지난주, 페이스 랜드마크 모델 테스트 5종류 테스트, 네트워크 만든것과 논문이 나와있는 종류로 포함해서 5종류, 속도가 괜찮은 모델 아리에게 전달, 시행착오에 노트 해놓음
글랜-노션에 정리하는 작업중, 게임디비 관련 이슈는 노션에 계속 공유중, 예전모델들이 업데이트가 덜된 부분이있어 추가할 예정, 레이너와 같이 하는 읽기 도우미 전반적으로 개발중에 있음 읽기 모델은 초기 단계에 있으며 여러가지 시도중에 있음, 배포 문제는 회의후에 결과가 나올예정,
윤 - 월요일에 68랜드마크 학습, 결과가 나와서 아카이브에 정리완료, 생각보다 로스가 0.03~0.06정도 나왔고 눈으로 학습시킨것보다는 성능이 낮음, 외부화 정리에 대해서는 아직 덜됐음, 다음주 수요일까지 근무.
하디 - 저번주 모델 학습을 할때 버그가 있어서 알아본 결과, ctc모델에서 input 데이터가 너무커서 소화를 못해버리는 버그가 있었음, Attn 방식으로 학습이 가능하다고 하여 회사 gpu서버에서 학습을 시작했고 학습이 진행중에 있음(Attn방식이 그래픽용량이 많이 사용되어서 회사 gpu서버에서 학습중), 추가 데이터로 책표지 4만장 이외에 textgenerator를 이용한 synthetic 데이터 포함 4만장을 추가로 구비하여 글랜 서버에 올려놓았음.


